{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b0d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    # to load dataset\n",
    "import numpy as np     # for mathematic equation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # to get collection of stopwords\n",
    "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
    "from tensorflow.keras.models import Sequential     # the model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e61ee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# importing the dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\ajayg\\Desktop\\CS\\Projects\\Sentimental analysis using LSTM\\IMDBDataset.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e834030",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2652c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews\n",
      "0        [one, reviewers, mentioned, watching, oz, epis...\n",
      "1        [a, wonderful, little, production, the, filmin...\n",
      "2        [i, thought, wonderful, way, spend, time, hot,...\n",
      "3        [basically, family, little, boy, jake, thinks,...\n",
      "4        [petter, mattei, love, time, money, visually, ...\n",
      "                               ...                        \n",
      "49995    [i, thought, movie, right, good, job, it, crea...\n",
      "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
      "49997    [i, catholic, taught, parochial, elementary, s...\n",
      "49998    [i, going, disagree, previous, comment, side, ...\n",
      "49999    [no, one, expects, star, trek, movies, high, a...\n",
      "Name: review, Length: 50000, dtype: object \n",
      "\n",
      "Sentiment\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        1\n",
      "        ..\n",
      "49995    1\n",
      "49996    0\n",
      "49997    0\n",
      "49998    0\n",
      "49999    0\n",
      "Name: sentiment, Length: 50000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv(r\"C:\\Users\\ajayg\\Desktop\\CS\\Projects\\Sentimental analysis using LSTM\\IMDBDataset.csv\")\n",
    "    x_data = df['review']       # Reviews/Input\n",
    "    y_data = df['sentiment']    # Sentiment/Output\n",
    "\n",
    "    # PRE-PROCESS REVIEW\n",
    "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
    "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
    "    \n",
    "    # ENCODE SENTIMENT -> 0 & 1\n",
    "    y_data = y_data.replace('positive', 1)\n",
    "    y_data = y_data.replace('negative', 0)\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "x_data, y_data = load_dataset()\n",
    "\n",
    "print('Reviews')\n",
    "print(x_data, '\\n')\n",
    "print('Sentiment')\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b767be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "1943     [i, saw, the, merchant, venice, london, last, ...\n",
      "29990    [this, terrible, movie, barely, recognizable, ...\n",
      "14429    [the, worst, movie, i, seen, yeah, fun, fantas...\n",
      "2384     [truly, wonderful, movie, bruce, willis, gives...\n",
      "25759    [everybody, wants, editor, watch, movie, it, s...\n",
      "                               ...                        \n",
      "23761    [know, read, countless, films, doubt, reading,...\n",
      "22640    [i, really, care, had, gotten, rid, comedy, sl...\n",
      "6771     [just, another, example, stepehn, king, books,...\n",
      "34318    [i, picked, film, based, plot, summary, critic...\n",
      "5034     [there, actually, good, reasons, person, take,...\n",
      "Name: review, Length: 40000, dtype: object \n",
      "\n",
      "10170    [i, know, people, think, movie, without, even,...\n",
      "39796    [please, help, economy, spend, money, elsewher...\n",
      "15324    [i, rather, disappointed, the, first, tetsuo, ...\n",
      "6195     [i, really, enjoyed, movie, in, my, dvd, colle...\n",
      "12120    [when, showed, seattle, int, l, film, fest, i,...\n",
      "                               ...                        \n",
      "6018     [this, almost, action, less, film, following, ...\n",
      "26934    [this, movie, second, worst, film, i, ever, se...\n",
      "42754    [there, little, fantastic, anne, rice, book, i...\n",
      "30593    [one, wonders, state, society, produce, father...\n",
      "424      [i, eagerly, awaited, first, screening, film, ...\n",
      "Name: review, Length: 10000, dtype: object \n",
      "\n",
      "Test Set\n",
      "1943     1\n",
      "29990    0\n",
      "14429    0\n",
      "2384     1\n",
      "25759    0\n",
      "        ..\n",
      "23761    0\n",
      "22640    0\n",
      "6771     0\n",
      "34318    1\n",
      "5034     0\n",
      "Name: sentiment, Length: 40000, dtype: int64 \n",
      "\n",
      "10170    1\n",
      "39796    0\n",
      "15324    0\n",
      "6195     1\n",
      "12120    1\n",
      "        ..\n",
      "6018     1\n",
      "26934    0\n",
      "42754    0\n",
      "30593    1\n",
      "424      0\n",
      "Name: sentiment, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "\n",
    "print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd97b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in x_train:\n",
    "        review_length.append(len(review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c35f9d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[   1  120    2 ...    0    0    0]\n",
      " [   8  290    3 ...    0    0    0]\n",
      " [   2  157    3 ...    0    0    0]\n",
      " ...\n",
      " [ 453   73  367 ...    0    0    0]\n",
      " [   1 1490    4 ...    0    0    0]\n",
      " [  50   75    9 ...  589    6  393]] \n",
      "\n",
      "Encoded X Test\n",
      " [[    1    47    20 ...     0     0     0]\n",
      " [  495   247  7686 ...     0     0     0]\n",
      " [    1   159   562 ...     0     0     0]\n",
      " ...\n",
      " [   50    48   714 ...   404   340  2670]\n",
      " [    5  3521   931 ...   979  7417   838]\n",
      " [    1  7181 12575 ...  3650   103   197]] \n",
      "\n",
      "Maximum review length:  130\n"
     ]
    }
   ],
   "source": [
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e5d9559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 130, 32)           2962816   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,987,713\n",
      "Trainable params: 2,987,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURE\n",
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model.add(LSTM(LSTM_OUT))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "906aeb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'models/LSTM.h5',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8bf7b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.9556\n",
      "Epoch 1: accuracy improved from 0.95117 to 0.95565, saving model to models\\LSTM.h5\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.1471 - accuracy: 0.9556\n",
      "Epoch 2/6\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9656\n",
      "Epoch 2: accuracy improved from 0.95565 to 0.96562, saving model to models\\LSTM.h5\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.1223 - accuracy: 0.9656\n",
      "Epoch 3/6\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9710\n",
      "Epoch 3: accuracy improved from 0.96562 to 0.97102, saving model to models\\LSTM.h5\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 0.1098 - accuracy: 0.9710\n",
      "Epoch 4/6\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9711\n",
      "Epoch 4: accuracy improved from 0.97102 to 0.97107, saving model to models\\LSTM.h5\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 0.1094 - accuracy: 0.9711\n",
      "Epoch 5/6\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.9595\n",
      "Epoch 5: accuracy did not improve from 0.97107\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 0.1367 - accuracy: 0.9595\n",
      "Epoch 6/6\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9751\n",
      "Epoch 6: accuracy improved from 0.97107 to 0.97513, saving model to models\\LSTM.h5\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 0.0966 - accuracy: 0.9751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b90a6ac3d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 128, epochs = 6, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f2f45b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0792 - accuracy: 0.9819\n"
     ]
    }
   ],
   "source": [
    "#evaluate our model\n",
    "result = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcfe26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71306a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Review: I sure would like to see a resurrection of a up dated Seahunt series with the tech they have today it would bring back the kid excitement in me.I grew up on black and white TV and Seahunt with Gunsmoke were my hero's every week.You have my vote for a comeback of a new sea hunt.We need a change of pace in TV and this would work for a world of under water adventure.Oh by the way thank you for an outlet like this to view many viewpoints about TV and the many movies.So any ole way I believe I've got what I wanna say.Would be nice to read some more plus points about sea hunt.If my rhymes would be 10 lines would you let me submit,or leave me out to be in doubt and have me to quit,If this is so then I must go so lets do it.\n"
     ]
    }
   ],
   "source": [
    "review = str(input('Movie Review: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4bc2688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned:  I sure would like to see a resurrection of a up dated Seahunt series with the tech they have today it would bring back the kid excitement in meI grew up on black and white TV and Seahunt with Gunsmoke were my heros every weekYou have my vote for a comeback of a new sea huntWe need a change of pace in TV and this would work for a world of under water adventureOh by the way thank you for an outlet like this to view many viewpoints about TV and the many moviesSo any ole way I believe Ive got what I wanna sayWould be nice to read some more plus points about sea huntIf my rhymes would be  lines would you let me submitor leave me out to be in doubt and have me to quitIf this is so then I must go so lets do it\n",
      "Filtered:  ['i sure would like see resurrection dated seahunt series tech today would bring back kid excitement mei grew black white tv seahunt gunsmoke heros every weekyou vote comeback new sea huntwe need change pace tv would work world water adventureoh way thank outlet like view many viewpoints tv many moviesso ole way i believe ive got i wanna saywould nice read plus points sea huntif rhymes would  lines would let submitor leave doubt quitif i must go lets']\n"
     ]
    }
   ],
   "source": [
    "# Pre-process input\n",
    "regex = re.compile(r'[^a-zA-Z\\s]')\n",
    "review = regex.sub('', review)\n",
    "print('Cleaned: ', review)\n",
    "\n",
    "words = review.split(' ')\n",
    "filtered = [w for w in words if w not in english_stops]\n",
    "filtered = ' '.join(filtered)\n",
    "filtered = [filtered.lower()]\n",
    "\n",
    "print('Filtered: ', filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a79aa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1   154    12     6    15  8554  1997 56916   108  5010   405    12\n",
      "    636    63   421  2358 23494  2080   219   356   142 56916 18687 14266\n",
      "     84  1967  6878    82  1565   265   573   950   142    12    74    85\n",
      "    867    26  1266 14255     6   548    36 12729   142    36 11382    26\n",
      "      1   166 16552    99     1  2919   236   241   827   717  1565 12287\n",
      "     12   316    12   181   469   704     1   112    62  1485     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "tokenize_words = token.texts_to_sequences(filtered)\n",
    "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
    "print(tokenize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba46ae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 353ms/step\n",
      "[[0.97409457]]\n"
     ]
    }
   ],
   "source": [
    "result = loaded_model.predict(tokenize_words)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e9ab13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "if result >= 0.7:\n",
    "    print('positive')\n",
    "else:\n",
    "    print('negative')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
